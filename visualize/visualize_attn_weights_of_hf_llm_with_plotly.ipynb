{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Union\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer(model_id: str, trust_remote_code: bool = False) -> AutoTokenizer:\n",
    "    \"\"\"\n",
    "    Load a tokenizer from the Hugging Face model.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The name of the model to load the tokenizer for.\n",
    "        trust_remote_code (bool, optional): Whether to trust remote code. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        AutoTokenizer: The loaded tokenizer.\n",
    "\n",
    "    Example:\n",
    "        >>> tokenizer = load_tokenizer(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "        >>> print(type(tokenizer))\n",
    "        <class 'transformers.models.auto.tokenization_auto.AutoTokenizer'>\n",
    "    \"\"\"\n",
    "    # Load the tokenizer from the Hugging Face model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=trust_remote_code)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def load_model(\n",
    "    model_name: str,\n",
    "    dtype: Union[str, torch.dtype] = \"bfloat16\",\n",
    "    device_map: Union[str, None] = \"auto\",\n",
    "    low_cpu_mem_usage: bool = True,\n",
    "    attn_implementation: str = \"eager\",\n",
    "    trust_remote_code: bool = False\n",
    ") -> AutoModelForCausalLM:\n",
    "    \"\"\"\n",
    "    Load a causal language model from the Hugging Face model.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model to load.\n",
    "        dtype (Union[str, torch.dtype], optional): The data type to load the model with. Defaults to \"bfloat16\".\n",
    "        device_map (Union[str, None], optional): The device map to use for loading the model. Defaults to \"auto\".\n",
    "        low_cpu_mem_usage (bool, optional): Whether to use low CPU memory usage. Defaults to True.\n",
    "        attn_implementation (str, optional): The attention implementation to use. Defaults to \"eager\".\n",
    "        trust_remote_code (bool, optional): Whether to trust remote code. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        AutoModelForCausalLM: The loaded model.\n",
    "\n",
    "    Example:\n",
    "        >>> model = load_model(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "        >>> print(type(model))\n",
    "        <class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>\n",
    "    \"\"\"\n",
    "    # Convert dtype string to torch dtype if necessary\n",
    "    if isinstance(dtype, str) and dtype != \"auto\":\n",
    "        dtype = getattr(torch, dtype)  # Convert dtype string to torch dtype\n",
    "\n",
    "    # Load the model from the Hugging Face model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=device_map,\n",
    "        low_cpu_mem_usage=low_cpu_mem_usage,\n",
    "        attn_implementation=attn_implementation,\n",
    "        trust_remote_code=trust_remote_code\n",
    "    ).eval()  # Set the model to evaluation mode\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention maps of multiple decoder blocks using Plotly's slider\n",
    "def visualize_attention_with_slider(\n",
    "    model: AutoModelForCausalLM,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    head_idx: Union[int, str, None] = \"mean\",\n",
    "    zmin: float = 0.0,\n",
    "    zmax: float = 1.0,\n",
    "    print_prompt: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualize attention maps of multiple decoder blocks using Plotly's animation (frames + slider) feature.\n",
    "    This function is designed for decoder-only models (e.g., GPT, LLaMA).\n",
    "\n",
    "    Args:\n",
    "        model (AutoModelForCausalLM): Pre-loaded model.\n",
    "        tokenizer (AutoTokenizer): Pre-loaded tokenizer.\n",
    "        input_ids (torch.Tensor): Input IDs of shape (batch_size, seq_len). Assumes batch_size=1.\n",
    "        head_idx (Union[int, str, None]):\n",
    "            - int: Visualize attention of the specified head.\n",
    "            - \"mean\"/None: Visualize the mean attention of all heads.\n",
    "        zmin (float): Minimum value for the color scale.\n",
    "        zmax (float): Maximum value for the color scale.\n",
    "        print_prompt (bool): If True, prints the input prompt.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If batch_size is not 1 or if head_idx is invalid.\n",
    "\n",
    "    Example:\n",
    "        >>> model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "        >>> input_ids = tokenizer.encode(\"Hello, world!\", return_tensors='pt')\n",
    "        >>> visualize_attention_slider(model, tokenizer, input_ids)\n",
    "    \"\"\"\n",
    "    # Ensure batch_size is 1\n",
    "    if input_ids.shape[0] != 1:\n",
    "        raise ValueError(\"This implementation only supports batch_size=1.\")\n",
    "\n",
    "    if print_prompt:\n",
    "        print(f\"Input prompt: \\n{tokenizer.batch_decode(input_ids)[0]}\")\n",
    "\n",
    "    # Create labels for the axes (format: \"i:token\")\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "    indexed_tokens = [f\"{i}:{tok}\" for i, tok in enumerate(tokens)]\n",
    "\n",
    "    # Perform inference and get attentions from all layers\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, output_attentions=True, use_cache=False)\n",
    "    all_attentions = outputs.attentions  # list: [layer_0, layer_1, ..., layer_(N-1)]\n",
    "    num_layers = len(all_attentions)\n",
    "\n",
    "    # Create frames for each block\n",
    "    frames = []\n",
    "    for block_idx in range(num_layers):\n",
    "        # Extract attention block (shape: (n_heads, seq_len, seq_len))\n",
    "        # all_attentions[block_idx] (shape: (batch_size=1, n_heads, seq_len, seq_len))\n",
    "        attn_block = all_attentions[block_idx][0]\n",
    "\n",
    "        # Select attention based on head_idx\n",
    "        if head_idx is None or head_idx == \"mean\":\n",
    "            attn_selected = attn_block.mean(dim=0)\n",
    "            title_suffix = \" (mean of all heads)\"\n",
    "        else:\n",
    "            if not (0 <= head_idx < attn_block.shape[0]):\n",
    "                raise ValueError(f\"head_idx={head_idx} is not a valid head index.\")\n",
    "            attn_selected = attn_block[head_idx]\n",
    "            title_suffix = f\" (head {head_idx})\"\n",
    "\n",
    "        attn_np = attn_selected.float().cpu().numpy()\n",
    "\n",
    "        # Create frame\n",
    "        frames.append(\n",
    "            go.Frame(\n",
    "                data=[\n",
    "                    go.Heatmap(\n",
    "                        z=attn_np,\n",
    "                        x=indexed_tokens,\n",
    "                        y=indexed_tokens,\n",
    "                        colorscale=\"YlGnBu\",\n",
    "                        zmin=zmin,\n",
    "                        zmax=zmax,\n",
    "                        zsmooth=False,\n",
    "                        colorbar=dict(\n",
    "                            title=dict(\n",
    "                                text=\"Attention<br>Score<br>&nbsp;\",\n",
    "                                side=\"top\",\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                ],\n",
    "                name=f\"Block_{block_idx}\",\n",
    "                layout=go.Layout(\n",
    "                    title=f\"Decoder Block {block_idx} Attention {title_suffix}\"\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Initialize figure with the first frame\n",
    "    fig = go.Figure(\n",
    "        data=frames[0].data,\n",
    "        layout=frames[0].layout,\n",
    "        frames=frames\n",
    "    )\n",
    "\n",
    "    # Create slider steps\n",
    "    steps = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [frame.name],  # Frame to play\n",
    "                {\"mode\": \"immediate\", \"frame\": {\"duration\": 0, \"redraw\": True}, \"transition\": {\"duration\": 0}},\n",
    "            ],\n",
    "            label=str(i),\n",
    "        )\n",
    "        steps.append(step)\n",
    "\n",
    "    # Slider configuration\n",
    "    sliders = [\n",
    "        dict(\n",
    "            active=0,\n",
    "            currentvalue={\"prefix\": \"Decoder Block: \"},\n",
    "            steps=steps,\n",
    "            x=0.05,            # X position of the slider (0=left, 1=right)\n",
    "            y=-0.30,           # Y position of the slider (negative to move below the plot)\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"top\",\n",
    "            pad={\"t\": 50},     # Padding around the slider\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Play/Pause buttons configuration\n",
    "    updatemenus = [\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            showactive=False,\n",
    "            x=1.20,\n",
    "            y=1.15,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"top\",\n",
    "            direction=\"left\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Play\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        None,\n",
    "                        {\"frame\": {\"duration\": 500, \"redraw\": True}, \"fromcurrent\": True, \"mode\": \"immediate\"},\n",
    "                    ],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"Pause\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        [None],\n",
    "                        {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\"},\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Finalize layout\n",
    "    fig.update_layout(\n",
    "        sliders=sliders,\n",
    "        updatemenus=updatemenus,\n",
    "        xaxis=dict(title=\"Key Tokens\"),\n",
    "        yaxis=dict(title=\"Query Tokens\", autorange=\"reversed\"),  # Reverse y-axis\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(t=100, b=100),  # Increase top and bottom margins\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model path and device\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = load_tokenizer(model_name)\n",
    "model = load_model(model_name, device_map=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The user prompt and tentative model response\n",
    "prompt: str = \"I want to go to Tokyo Tower. What station should I get off at?\"\n",
    "tentative_response: str = \"Please get off at Akabanebashi Station on the Oedo Line.\"\n",
    "\n",
    "\n",
    "# Prepare message list for chat template\n",
    "messages: list[dict[str, str]] = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "    {\"role\": \"assistant\", \"content\": tentative_response}\n",
    "]\n",
    "\n",
    "# Apply chat template (model-specific preprocessing)\n",
    "prompt_with_chat_template: str = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "\n",
    "# Process inputs (tokenize and prepare input_ids for model input)\n",
    "inputs: dict[str, torch.Tensor] = tokenizer(\n",
    "    text=prompt_with_chat_template, return_tensors=\"pt\", add_special_tokens=False\n",
    ").to(device)\n",
    "input_ids: torch.Tensor = inputs[\"input_ids\"].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how many heads of the attention map should be visualized\n",
    "# head_idx = 0     # Visualize the attention of the first head\n",
    "head_idx = \"mean\"  # Visualize the mean attention of all heads\n",
    "\n",
    "# Visualize the attention map with a slider\n",
    "visualize_attention_with_slider(model, tokenizer, input_ids, head_idx, zmax=0.1, print_prompt=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/attention_map_with_decoder_slider.png\" alt=\"attention_map_with_decoder_slider\" width=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention maps of multiple decoder blocks using Plotly's slider (with font-size slider)\n",
    "def visualize_attention_with_slider_and_fontsize(\n",
    "    model: AutoModelForCausalLM,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    head_idx: Union[int, str, None] = \"mean\",\n",
    "    zmin: float = 0.0,\n",
    "    zmax: float = 1.0,\n",
    "    print_prompt: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualizes attention maps of multiple decoder blocks with a slider to switch between blocks.\n",
    "    Additionally, includes a slider to dynamically change the font size of axis labels.\n",
    "    Assumes a decoder-only model (e.g., GPT, LLaMA).\n",
    "\n",
    "    Args:\n",
    "        model (AutoModelForCausalLM): Pre-loaded model.\n",
    "        tokenizer (AutoTokenizer): Pre-loaded tokenizer.\n",
    "        input_ids (torch.Tensor): Input IDs of shape (batch_size, seq_len). Assumes batch_size=1.\n",
    "        head_idx (Union[int, str, None]):\n",
    "            - int: Visualize attention of the specified head.\n",
    "            - \"mean\"/None: Visualize mean attention of all heads.\n",
    "        zmin (float): Minimum value for the color scale.\n",
    "        zmax (float): Maximum value for the color scale.\n",
    "        print_prompt (bool): If True, prints the input prompt before visualization.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If batch_size is not 1 or if head_idx is invalid.\n",
    "\n",
    "    Example:\n",
    "        >>> model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "        >>> input_ids = tokenizer.encode(\"Hello, world!\", return_tensors='pt')\n",
    "        >>> visualize_attention_slider_with_fontsize(model, tokenizer, input_ids)\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Preprocessing: Assumes batch_size=1\n",
    "    # --------------------------------------------------\n",
    "    if input_ids.shape[0] != 1:\n",
    "        raise ValueError(\"Current implementation only supports batch_size=1.\")\n",
    "\n",
    "    if print_prompt:\n",
    "        print(f\"Input Prompt: \\n{tokenizer.decode(input_ids[0])}\")\n",
    "\n",
    "    # Create axis labels in \"i:token\" format to avoid overlapping categories\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "    indexed_tokens = [f\"{i}:{tok}\" for i, tok in enumerate(tokens)]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Model inference to get attentions from all layers\n",
    "    # --------------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            output_attentions=True,\n",
    "            use_cache=False  # Recommended to set False to fully visualize causal mask\n",
    "        )\n",
    "    all_attentions = outputs.attentions  # list: [layer_0, layer_1, ..., layer_(N-1)]\n",
    "    num_layers = len(all_attentions)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Create attention maps as frames (for animation)\n",
    "    # --------------------------------------------------\n",
    "    frames = []\n",
    "    for block_idx in range(num_layers):\n",
    "        # Extract attention block (shape: (n_heads, seq_len, seq_len))\n",
    "        # all_attentions[block_idx] (shape: (batch_size=1, n_heads, seq_len, seq_len))\n",
    "        attn_block = all_attentions[block_idx][0]\n",
    "\n",
    "        # Select attention based on head_idx\n",
    "        if head_idx is None or head_idx == \"mean\":\n",
    "            attn_selected = attn_block.mean(dim=0)\n",
    "            title_suffix = \" (mean of all heads)\"\n",
    "        else:\n",
    "            if not (0 <= head_idx < attn_block.shape[0]):\n",
    "                raise ValueError(f\"head_idx={head_idx} is not a valid head number.\")\n",
    "            attn_selected = attn_block[head_idx]\n",
    "            title_suffix = f\" (head {head_idx})\"\n",
    "\n",
    "        attn_np = attn_selected.float().cpu().numpy()\n",
    "\n",
    "        # Create frame\n",
    "        frames.append(\n",
    "            go.Frame(\n",
    "                data=[\n",
    "                    go.Heatmap(\n",
    "                        z=attn_np,\n",
    "                        x=indexed_tokens,\n",
    "                        y=indexed_tokens,\n",
    "                        colorscale=\"YlGnBu\",\n",
    "                        zmin=zmin,\n",
    "                        zmax=zmax,\n",
    "                        zsmooth=False,\n",
    "                        colorbar=dict(\n",
    "                            title=dict(\n",
    "                                text=\"Attention<br>Score<br>&nbsp;\",\n",
    "                                side=\"top\",\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                ],\n",
    "                name=f\"Block_{block_idx}\",\n",
    "                layout=go.Layout(\n",
    "                    title=f\"Decoder Block {block_idx} Attention {title_suffix}\"\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Set initial state (Block_0) to Figure\n",
    "    # --------------------------------------------------\n",
    "    fig = go.Figure(\n",
    "        data=frames[0].data,\n",
    "        layout=frames[0].layout,\n",
    "        frames=frames\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1) Slider for switching blocks (animation)\n",
    "    # --------------------------------------------------\n",
    "    steps = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        step = dict(\n",
    "            method=\"animate\",\n",
    "            args=[\n",
    "                [frame.name],  # Frame name to play\n",
    "                {\n",
    "                    \"mode\": \"immediate\",\n",
    "                    \"frame\": {\"duration\": 0, \"redraw\": True},\n",
    "                    \"transition\": {\"duration\": 0},\n",
    "                },\n",
    "            ],\n",
    "            label=str(i),\n",
    "        )\n",
    "        steps.append(step)\n",
    "\n",
    "    block_slider = dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Decoder Block: \"},\n",
    "        steps=steps,\n",
    "        x=0.05,\n",
    "        y=-0.35,  # Position below the figure (adjust as needed)\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"top\",\n",
    "        pad={\"t\": 50},\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2) Slider for changing font size (layout update)\n",
    "    # --------------------------------------------------\n",
    "    # Example: 4, 5, 6, 7, 8, 9, 10, 15 (8 steps)\n",
    "    font_sizes = [4, 5, 6, 7, 8, 9, 10, 15]\n",
    "    font_steps = []\n",
    "    for size in font_sizes:\n",
    "        step = dict(\n",
    "            method=\"relayout\",\n",
    "            args=[{\"xaxis.tickfont.size\": size, \"yaxis.tickfont.size\": size}],\n",
    "            label=str(size),\n",
    "        )\n",
    "        font_steps.append(step)\n",
    "\n",
    "    font_slider = dict(\n",
    "        active=6,  # Default selection (index in the list)\n",
    "        currentvalue={\"prefix\": \"Font Size: \"},\n",
    "        steps=font_steps,\n",
    "        x=0.05,\n",
    "        y=-0.55,  # Position below block_slider\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"top\",\n",
    "        pad={\"t\": 50},\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Set sliders\n",
    "    # --------------------------------------------------\n",
    "    fig.update_layout(sliders=[block_slider, font_slider])\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Play/Pause buttons (updatemenus) positioned at the top right\n",
    "    # --------------------------------------------------\n",
    "    updatemenus = [\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            showactive=False,\n",
    "            x=1.10,\n",
    "            y=1.15,\n",
    "            xanchor=\"right\",\n",
    "            yanchor=\"top\",\n",
    "            direction=\"left\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Play\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 500, \"redraw\": True},\n",
    "                            \"fromcurrent\": True,\n",
    "                            \"mode\": \"immediate\",\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"Pause\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        [None],\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 0, \"redraw\": True},\n",
    "                            \"mode\": \"immediate\",\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Finalize layout\n",
    "    # --------------------------------------------------\n",
    "    fig.update_layout(\n",
    "        updatemenus=updatemenus,\n",
    "        xaxis=dict(title=\"Key Tokens\", tickfont=dict(size=10)),  # Default font size\n",
    "        yaxis=dict(title=\"Query Tokens\", autorange=\"reversed\", tickfont=dict(size=10)),\n",
    "        width=940,\n",
    "        height=1200,\n",
    "        margin=dict(t=120, b=120),\n",
    "    )\n",
    "\n",
    "    # Display\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how many heads of the attention map should be visualized\n",
    "# head_idx = 0     # Visualize the attention of the first head\n",
    "head_idx = \"mean\"  # Visualize the mean attention of all heads\n",
    "\n",
    "# Visualize the attention map with a decoder block slider and font size slider\n",
    "visualize_attention_with_slider_and_fontsize(model, tokenizer, input_ids, head_idx, zmax=0.1, print_prompt=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/attention_map_with_decoder_and_fontsize_slider.png\" alt=\"attention_map_with_decoder_and_fontsize_slider\" width=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
